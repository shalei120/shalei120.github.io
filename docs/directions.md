
# Research 1：医学常识信息图自动构建

<span style="color:#29261B">构建覆盖全科医学知识的高质量知识图</span>

<span style="color:#29261B">包括疾病、症状、检查、治疗、用药指南等各种医学要素及其关系</span>

<span style="color:#29261B">从各种医学文献、指南、教材等海量非结构化数据中自动抽取并持续更新</span>

# Research 1.1 医学常识图 LLM对齐（陈冠桦）

* 目的： <span style="color:#29261B">赋予大模型结构化的医学常识知识</span>  <span style="color:#29261B">，</span>  <span style="color:#29261B">使其能够更好地理解和推理医学领域的</span> 概念和事物之间的关系
* 优势：
  * 医学文档主要是非结构化的自然语言形式，需要模型自行提取和建模其中的知识。而常识图谱则是结构化的三元组知识表示，更加精炼和明确。
  * 知识完整性：海量文档知识分散、重复冗余，很难确保知识的完整性和一致性。常识图谱则经过了系统构建，力求全面覆盖医学知识，减少遗漏。
  * 知识质量：文档中的知识存在噪音、错误，需要模型自行识别和过滤。而常识图谱通常来自权威可靠来源，经过了多轮审核与清洗。
  * 推理能力：直接预训练很难让模型学习到概念之间的关系推理规则。而常识图谱蕴含了大量的逻辑关系知识，有助于提升模型的推理能力。
  * 可解释性：通过常识图谱对齐，模型掌握了明确的知识结构，其决策过程将更加可解释，符合人类认知模式。

# 研究问题：如何将LLM与图结构知识对齐？
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.1：针对大型语言模型(LLM)缺乏结构化知识表示和复杂推理能力的问题，探究将图结构知识与LLM进行对齐和融合的方法，优化LLM在知识密集型任务中的表现；研究基于图神经网络的知识表示学习和推理机制，优化LLM在实体和关系理解、多跳推理方面的能力；构建融合知识图谱信息的语言模型训练范式，并开发知识引导的文本生成和问答系统。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.2：针对LLM与图结构知识结合后的可解释性问题，探究模型决策过程的可视化和分析技术，优化模型行为的透明度和可信度；研究基于图结构知识的推理解释生成方法，优化模型输出的可解释性；构建用户友好的交互式系统，并支持用户对模型决策过程进行探索和反馈。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.3：针对将LLM与知识图谱对齐后的评估和应用问题，探究综合考虑语言建模和知识匹配的评估指标，优化模型性能的衡量标准；研究将知识增强的LLM应用于智能问答、知识总结、决策支持等场景，优化实际任务中的表现；构建开放的评测基准和工具包，并促进研究社区的交流与合作。
</div>

# 研究问题：如何动态编辑模型参数使其加入少量新知识？（1）
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.4：针对现有预训练语言模型难以灵活添加新知识的问题，探究动态编辑模型参数的方法，优化模型快速适应新知识的能力；研究基于梯度编辑和参数更新的技术，优化模型在加入新知识后的稳定性和性能；构建支持增量学习的模型架构，并开发用户友好的知识编辑接口。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.5：针对动态编辑过程中的知识选择和融合问题，探究知识表示与模型参数的映射机制，优化新知识的高效注入方式；研究知识冲突检测和调解策略，优化模型在融合新知识时的一致性和鲁棒性；构建知识感知的参数编辑框架，并引入知识约束和正则化技术，确保编辑后模型的合理性。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.6：针对编辑后模型的泛化和遗忘问题，探究参数稀疏化和模块化技术，优化模型在保留原有知识的同时，对新知识的快速适应；研究基于元学习的参数编辑范式，优化模型在多个编辑任务上的迁移和泛化能力；构建动态评估和反馈机制，并及时调整编辑策略，防止模型对原有知识的遗忘。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.7：针对动态编辑的可解释性和可控性问题，探究模型参数变化的可视化和分析技术，优化编辑过程的透明度和可解释性；研究基于因果推理和反事实生成的编辑策略，优化模型行为的可控性和合理性；构建交互式的编辑系统，并支持用户对编辑结果进行解释和反馈，增强用户对模型的信任和控制。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.8：针对动态编辑在实际应用中的部署和优化问题，探究编辑过程的高效计算和加速技术，优化实时交互和响应的性能；研究面向特定领域和任务的参数编辑方法，优化模型在垂直场景下的适用性和有效性；构建开放的编辑工具包和开发平台，并鼓励社区贡献和共享知识编辑资源，促进技术的普及和应用。

</div>

# 研究问题：基于大模型与知识库融合的幻觉缓解技术研究

* 难点：幻觉是如何产生的呢
* 数据来源
  * LLM 幻觉的主要原因之⼀在于用于训练 LLM 的训练数据。这些数据大部分是基于比如互联网上的各种新闻、文章、书籍、网站等覆盖的文本资料。虽然这些数据⼀定程度上提供了有价值的语言模式，但它也不可避免会包含⼀些不准确的信息，如果训练数据中包含⼀些矛盾或者错误的表述，就可能导致 LLM 也在学习这些错误的表达，从而⼀定程度导致了幻觉的产生。
* 模型预训练阶段
  * 架构缺陷：基于前⼀个 token 预测下⼀个 token，这种单向建模阻碍了模型捕获复杂的上下文关系的能力；自注意力模块存在缺陷，随着 token 长度增加，不同位置的注意力被稀释。
  * 曝露偏差：训练策略也有缺陷，模型推理时依赖于自己生成的 token 进行后续预测，模型生成的错误 token 会在整个后续 token 中产生级联错误。


* 对齐阶段
  * 能力错位：大模型内在能力与标注数据中描述的功能之间可能存在错位。当对齐数据需求超出这些预定义的能力边界时，大模型会被训练来生成超出其自身知识边界的内容，从而放大幻觉的风险。
  * 信念错位：基于 RLHF 等的微调，使大模型的输出更符合人类偏好，但有时模型会倾向于迎合人类偏好，从而牺牲信息真实性。
* 推理阶段
  * 随机性抽样：在生成内容时根据概率随机生成。
  * 不完美的解码表示：上下文关注不足（过度关注相邻文本而忽视了源上下文）和 softmax 瓶颈（输出概率分布的表达能⼒受限）。
* 综上所述，幻觉产生在大模型建模的各个环节，想要彻底解决幻觉是相当困难的，当前针对幻觉现象有较多的研究，包括基于规则后处理、自动化打分、幻觉分类模型等，但是存在准确率不高、迁移泛化能力较差的问题。知识库作为高可信的知识来源，包括公开知识库和业务知识库等，能够有效验证数据的准确性，目前将知识库与大模型生成内容结合的研究主要集中在知识库本身的优化，或者基于规则策略的后处理，如何将知识库与大模型进行更有效的结合，在模型层面对大模型的生成内容进行有效提高还需要进⼀步研究。

<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
 指南1.8：基于知识库的自动化幻觉检测识别，基于知识库对大模型生成的过程、结果进行自动化幻觉检测，并指导大模型提升生成质量；
</div>



<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.9：基于知识库与大模型融合的模型结构设计、微调方法优化，探索更高效的模型结构，将知识库与大模型进行深度整合，在预训练、微调阶段进行融合，提升大模型知识理解能力和生成质量。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南1.10：大模型目前存在生成数据与世界知识不一致的问题，分析比较模型在正常输出与幻觉状态时的分布差异，通过监测不同状态下神经元的活动模式，分析导致幻觉现象的神经元或神经元集群，在此基础上构造针对性的优化策略来降低模型的扰动，缓解幻觉现象发生的概率。
</div>
可选评价：

幻觉检测准确率：在以下可选数据集上检测准确率、召回率、AUROC 等评估指标上高于 SOTA； 可参考 UHGEval、CHEF、Xsum、X\-Fact 等公开数据集

幻觉缓解效果：在公开数据集上幻觉生成比率低于 5%

业务场景验证正向效果：店员 copilot，汽车法律法规问答，医学问答

# Research2：决策agent，根据病历，症状判断该作的检查（王昊）

利用拥有的数据构造对齐数据集

构建工具接口

决策对齐

# 研究问题：在对齐数据较少时，如何完成精调？
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.1：针对对齐数据稀缺导致精调效果不佳的问题，探究少样本学习和半监督学习方法，优化模型在数据匮乏情况下的适应能力；研究数据增强和数据生成技术，优化对齐数据的规模和多样性；构建面向小样本精调的模型架构，并引入先验知识和迁移学习策略，提升精调效果。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.2：针对对齐数据分布与目标任务不一致的问题，探究域自适应和域泛化技术，优化模型在跨域精调中的鲁棒性；研究元学习和自适应优化算法，优化模型在不同任务间的快速适应能力；构建多任务和多域学习框架，并利用对抗训练和样本权重调整策略，增强模型的泛化性能。

</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.3：针对对齐数据标注质量不高的问题，探究噪声标签学习和弱监督学习方法，优化模型对低质量标注的容错能力；研究主动学习和交互式学习范式，优化标注过程的效率和准确性；构建质量感知的损失函数和训练策略，并引入多示例学习和标签净化技术，提升模型的学习效果。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.4：针对对齐数据不平衡和长尾分布的问题，探究数据再平衡和数据重要性采样技术，优化模型对稀有类别的学习能力；研究度量学习和对比学习方法，优化模型在不平衡数据上的特征表示能力；构建自适应的损失权重调整机制，并引入类别平衡和频率补偿策略，缓解数据不平衡带来的负面影响。
</div>


# 研究问题：缓解灾难性遗忘

大模型技术在垂域落地过程中主要的优化方法是基于垂域知识数据的微调。然后在垂域知识注入及学习的过程中，经常会表现出在新知识学习和注入的过程中对通用知识及能力上的降低。

当前解决灾难性遗忘问题的方法主要包括增量学习和重放记忆。然而，这些方法往往存在⼀些局限性。例如增量学习需要大量的计算资源和数据，并且容易导致过拟合；而重放记忆则需要维护⼀个庞大的记忆库，造成存储和计算的负担。因此，我们迫切需要⼀种高效的方法来缓解灾难性遗忘问题。

# 灾难性遗忘研究指南

<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.5：灾难性遗忘机理研究：深入分析灾难性遗忘的产生原因，探究不同因素对遗忘程度的影响，为后续研究提供理论基础。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.6：优化算法研究：以下方向三选一即可

a. 研究增量预训练中灾难性遗忘缓解技术，例如块扩展，让 LLMs 进行Transformer 块扩展后，增量预训练过程中仅对新增块进行训练，有效地进行模型知识注入，并且极大程度地避免灾难性遗忘；

b. 研究微调中灾难性遗忘缓解技术，例如 LoRAMoE，将 LoRA（低秩适配）和MoE（专家混合）技术融合在⼀起，旨在保留 LLMs 的世界知识的同时，仍允许进行特定任务的微调，降低灾难性遗忘对模型性能的影响，提高模型的泛化能力；

c. 研究持续学习中灾难性遗忘缓解技术，例如正则化方法、记忆回放方法和参数隔离等方法，为了扩展模型的适应能力，让模型能够在不同时刻学习不同任务的知识，即模型学习到的数据分布，持续学习算法必须在保留旧知识与学习新知识之间取得平衡。
</div>

# Research2.1 决策Agent检索增强（李昊）

仅使用对齐数据增强大模型本身的能力（或许不够）

加入医学常识图信息\+医学文本数据 检索增强 ✔️

# 研究问题：LLM如何利用超长上下文训练推理？

<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.7：针对超长上下文中的信息冗余和噪声问题，探究基于关键信息提取和摘要生成的预处理技术，优化输入序列的信噪比和语义浓度；研究自适应的注意力稀疏化机制，优化模型在冗长文本中的重点关注和信息筛选能力；构建多粒度的上下文表示框架，并引入层次化的编码和解码策略，实现对超长文本的高效压缩和信息萃取。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.8：针对超长上下文推理中的逻辑一致性和连贯性问题，探究基于图神经网络和关系推理的建模方法，优化模型在复杂推理链中的逻辑捕捉和连贯表达能力；研究基于知识增强和因果推断的推理策略，优化模型在长文本推理中的常识利用和因果分析能力；构建面向超长推理的评估基准和生成任务，并引入一致性约束和连贯性奖励机制，提升模型生成内容的逻辑合理性。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.9：针对超长上下文推理中的计算瓶颈和资源限制问题，探究模型压缩和知识蒸馏技术，优化推理过程的时空效率和资源利用率；研究基于张量分解和低秩近似的参数优化方法，优化模型在超长序列处理中的内存占用和计算开销；构建面向超长推理的分布式训练和推断框架，并引入模型并行和数据并行策略，实现大规模语料上的高效训练和部署。
</div>

# 研究问题：如何利用图结构信息进行检索增强

<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.10：针对传统检索方法忽略数据内在图结构导致检索质量不高的问题，探究基于图神经网络和图表示学习的检索模型，优化检索过程对数据复杂拓扑结构的建模和利用能力；研究图结构感知的相关性计算和排序算法，优化图结构信息在查询-文档匹配中的应用，提升检索结果的准确性和相关性；构建端到端的图结构检索框架，并引入多种图神经网络模型和图相似度计算方法，实现图结构数据的高效检索和查询。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.11：针对图结构数据的异构性和动态演化特点带来的检索挑战，探究异构图表示学习和动态图嵌入方法，优化检索模型对不同类型节点和边的语义表示能力；研究时序图神经网络和图演化模型，优化图结构数据随时间变化的表示学习和更新机制，增强检索模型的适应性和鲁棒性；构建图结构流数据的增量式检索框架，并引入图数据流的在线学习和索引技术，实现图结构数据的实时检索和持续更新。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南2.12：针对图结构数据的高维稀疏性和计算复杂度问题，探究图结构数据的降维和稀疏化表示方法，优化图数据在检索中的存储和计算效率；研究基于图采样和图压缩的计算加速技术，优化大规模图数据在检索过程中的处理速度和资源消耗；构建分布式图检索系统和并行计算架构，并引入图数据分区和负载均衡策略，实现高效可扩展的图结构检索服务。
</div>

# 研究问题：RAG 回复生成关键技术研究


* 指南2.13：算法需要在以下 2\+个能力上有所提升：
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
   正确检索信息的抽取和回复生成能力
</div>
   <div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">多篇章、跨文档等长跨度的信息整合能力</div>
   <div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">对抗检索噪声信息（相似信息、大量无关信息）的能力</div>
   <div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">对抗反事实性检索内容的能力</div>

* 目标：
  * 选择或者构建针对性的评测集和评测指标（开源参考RGB 评测集：https://arxiv\.org/pdf/2309\.01431\.pdf），数据集规模>500
  * 选择 2\+项研究内容，在参数规模 7B 左右的模型上，完成关键技术研究，并在评测集上，实现指标上 30%\+的效果提升


# Research 3:多模态大模型Agent（俞文翰）

浦医2\.0 ：460万张医学图像，涵盖分割与病理

浦医2\.0新增5个开源数据集，其中包括目前规模最大的医学图像分割数据集SA\-Med2D\-20M。该数据集由上海AI实验室与四川大学联合团队推出，拥有460万张医学图像及1970万个相应的掩膜，涵盖了10种模态、31个主要器官和219个类别标签，几乎覆盖人体所有部位，具备显著的数据多样性。

医学图像 大模型解析

心电图。。。

脑波。。。

# 如何使得已有的文本大模型快速理解医学图像、心电图、脑电图等模态信息？（1）

<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南3.1：针对现有文本大模型难以直接处理医学图像、心电图、脑电图等非文本模态信息的问题，探究跨模态表示学习和对齐技术，优化模型在不同模态间的信息融合和语义理解能力；研究基于预训练的跨模态转换和编码方法，优化文本大模型在医学多模态数据上的快速适应和泛化能力；构建医学多模态预训练框架，并引入模态对齐和模态蒸馏策略，实现文本大模型在医学场景下的高效迁移学习。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南3.2：针对医学多模态数据的异构性和复杂性问题，探究模态特异性表示学习和分层建模技术，优化模型对不同模态数据的特征提取和语义抽象能力；研究基于图神经网络和注意力机制的多模态融合方法，优化模型在处理医学图文、时空序列等复杂数据时的推理和决策能力；构建医学知识增强的多模态表示空间，并引入领域本体和知识图谱，增强文本大模型在医学场景下的背景理解和推理能力。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南3.3：针对医学多模态数据标注成本高、样本量有限的问题，探究少样本学习和主动学习策略，优化模型在标注数据稀缺情况下的学习效率和性能表现；研究基于对比学习和自监督学习的预训练方法，优化文本大模型在无标注医学多模态数据上的特征捕获和表示能力；构建医学多模态数据增强和生成框架，并引入模态转换和跨模态生成技术，扩充训练样本的规模和多样性。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">

指南3.4：针对医学多模态场景下的可解释性和可信度问题，探究面向医学决策的可解释性建模技术，优化模型输出结果的透明度和临床可解释性；研究基于因果推理和反事实生成的解释方法，优化模型在医学推理过程中的逻辑合理性和因果一致性；构建面向医生用户的交互式解释工具，并支持用户对模型决策过程进行探索、质疑和反馈，增强人机协同下的医学决策可信度。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南3.5：针对医学多模态大模型的部署和应用问题，探究模型压缩和加速技术，优化模型在医疗设备和移动端的实时性和资源效率；研究联邦学习和隐私保护算法，优化模型在分布式医疗数据场景下的安全性和隐私性；构建面向临床应用的医学多模态大模型开发平台，并提供可视化开发工具和API接口，促进模型在医疗实践中的应用和推广。
</div>


# 如何使得已有的文本/多模态大模型获得图像的细粒度理解？

<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南3.6：针对现有文本/多模态大模型缺乏对图像细节和局部特征的捕获能力问题，探究基于区域建议和注意力机制的细粒度图像表示学习技术，优化模型在图像理解中的空间定位和局部聚焦能力；研究层次化和多尺度的图像特征提取方法，优化模型对图像不同粒度语义信息的编码和融合能力；构建面向细粒度图像理解的多任务学习框架，并引入目标检测、语义分割等辅助任务，增强模型对图像细节的感知和理解能力。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南3.7：针对图像细粒度标注数据稀缺和获取成本高的问题，探究弱监督和半监督学习策略，优化模型在有限标注数据下的细粒度学习效率和性能表现；研究基于图像-文本对比学习和跨模态对齐的预训练方法，优化模型在无标注图像数据上的细粒度表示能力；构建图像细粒度描述生成和问答任务，并利用文本信息对图像细节进行自监督标注，扩充细粒度学习的训练样本。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南3.8：针对细粒度图像理解中的语义鸿沟和跨模态对齐问题，探究基于场景图和知识图谱的图像-文本语义建模技术，优化模型在图像细节与文本概念之间的映射和对齐能力；研究基于视觉问答和图文生成的交互式学习范式，优化模型通过问答交互获取图像细粒度信息的能力；构建多模态融合的图像理解框架，并引入跨模态注意力和对齐损失，提升模型在细粒度语义理解中的性能。
</div>

# Research 4：综合分析多种检验结果，给结论，给解释（张迪）

* 根据血样，医学图像等，给出结论，分析每一个检验结果和症状中指向该疾病的因素
* Trustworthy LLM inference
* LLM symbolic reasoning
* <span style="color:#29261B">诊断结论</span>  <span style="color:#29261B">: </span>  <span style="color:#29261B">xxxx</span>
* <span style="color:#29261B">诊断依据：</span>
  * <span style="color:#29261B">理论依据</span>  <span style="color:#29261B">:</span>  <span style="color:#29261B"> </span>  <span style="color:#29261B">xxxx</span>  <span style="color:#29261B">【</span>  <span style="color:#29261B">某医学教材第</span>  <span style="color:#29261B">xx</span>  <span style="color:#29261B">章</span>  <span style="color:#29261B">】【</span>  <span style="color:#29261B">论文</span>  <span style="color:#29261B">1】</span>
  * <span style="color:#29261B">观测症状：</span>  <span style="color:#29261B">xxx</span>  <span style="color:#29261B"> 说明 （</span>  <span style="color:#29261B">xxxx</span>  <span style="color:#29261B">）（例：</span>  <span style="color:#29261B">汗湿</span>  <span style="color:#29261B">:</span>  <span style="color:#29261B">由于疼痛刺激，交感神经兴奋，引起血管扩张、汗腺分泌过多所致</span>  <span style="color:#29261B">）</span>
  * 检验结果分析： <span style="color:#29261B">xxx</span>  <span style="color:#29261B"> 说明 （</span>  <span style="color:#29261B">xxxx</span>  <span style="color:#29261B">）（例：</span>  <span style="color:#29261B"> CEA</span>  <span style="color:#29261B">和</span>  <span style="color:#29261B">CA19\-9</span>  <span style="color:#29261B">是胃癌常见的肿瘤相关抗原，其显著升高提示存在胃肠道恶性肿瘤。 </span>  <span style="color:#29261B">）</span>

# 研究问题：LLM生成的重要信息，如何准确的找到其依据？

<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南4.1：针对LLM生成内容的可解释性和可追溯性不足的问题，探究基于注意力机制和归因分析的生成过程可视化技术，优化模型输出与输入之间的关联和依赖关系的透明度；研究基于因果推理和反事实生成的可解释性方法，优化模型在生成重要信息时的因果依据和逻辑链条的合理性；构建LLM生成过程的可解释性评估框架，并引入人工评估和自动评估指标，量化模型生成内容的可追溯性和依据充分性。
</div>

# 此处同样有LLM灾难性遗忘问题，见2.5-2.6

# Research 5：Miscellaneous

如何利用类似Neural ODE结构建模大模型？
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南5.1：针对传统大模型参数冗余和计算效率低下的问题，探究基于Neural ODE的参数化函数表示方法，优化模型参数的紧致性和表达能力；研究基于ODE积分的连续深度架构设计，优化模型深度和宽度的灵活调节，提升模型的计算效率和泛化能力；构建基于Neural ODE的大模型压缩和加速框架，并引入模型蒸馏和量化技术，实现模型性能和效率的平衡。
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南5.2：针对大模型在长序列建模和长程依赖捕捉方面的局限性，探究基于Neural ODE的连续时间建模方法，优化模型对变长序列的表示和建模能力；研究基于注意力机制和记忆模块的ODE架构设计，优化模型在长程信息传递和依赖捕捉中的有效性，增强模型在长文本和时序数据处理中的性能；构建基于Neural ODE的长序列生成和预测任务，并引入持续学习和增量更新机制，实现大模型在长序列数据流上的在线学习和适应。
</div>

如何加速大模型的训练和推理？加入新的高速架构？

<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
指南5.3：针对大模型训练和推理速度慢的问题，探究新的高效的模型架构和计算方式，研究类似低秩映射，speculative decoding等加速训练、微调或推理的方法，在保证模型性能的同时显著提升训练推理速度。
设计有效的压缩和剪枝算法：压缩和剪枝算法需要考虑模型的结构特点、任务需求以及压缩后的模型性能等因素，并进行合适的权衡和调整。参考方向：
<ul>
<li>1）稀疏化 Sparsity；</li>
<li>2）剪枝 Pruning；</li>
<li>3）知识蒸馏 Knowledge Distillation</li>
</ul> 等，通过优化或者组合优化的方式提升压缩和剪枝算法的效率。预期完成率：在某⼀个具体的算法上完成压缩或者剪枝策略的实现与优化，超越当前最优算法模型的压缩性能 20%以上，目标预期完成率 50%以上；
</div>
<div style="background-color: #f0f0f0; border: 2px solid #888; border-radius: 10px; padding: 15px;">
探索低精度推理算法：大模型低精度推理的放法是一种有效降低计算成本的途径，参考方向：<ul>
<li>1）量化 Quantization 技术；</li>
<li>2）通道精度分离 Channel-wise Precision Separation；</li>
<li>3）稀疏推理 Sparse Inference </li>
</ul> 等，通过精度和效率的有效折中，可以寻找最优的低精度推理算法。预期完成率：在某⼀个具体的算法上完成低精度推理的实现与优化，超越当前最优算法模型的量化性能 20%以上，目标预期完成率 50%以上；
</div>

# 

